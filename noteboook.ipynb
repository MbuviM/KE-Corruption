{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet pypdf\n",
    "# %pip install langchain\n",
    "# %pip install \n",
    "#%pip install langchain-huggingface\n",
    "#%pip uninstall transformers huggingface_hub sentence-transformers -y\n",
    "#%pip install transformers==4.28.1 huggingface_hub==0.14.1 sentence-transformers==2.2.0\n",
    "#%pip install -U sentence-transformers\n",
    "#%pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF Document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import *\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'EACC-NATIONAL-SURVEY-REPORT-2023.pdf', 'page': 0}, page_content='National Ethics and Corruption Survey (NECS) 2023\\nEACC Research Report No. 15 of December 2023iNATIONAL ETHICS AND \\nCORRUPTION SURVEY \\n(NECS), 2023\\nEVIDENCE FROM \\nHOUSEHOLDS IN KENYA\\nTuangamize UÔ¨Åsadi, Tuijenge Kenya\\nETHICS AND ANTI-CORRUPTION COMMISSION\\nEACC Research Report No. 15 of December 2023   ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"EACC-NATIONAL-SURVEY-REPORT-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'EACC-NATIONAL-SURVEY-REPORT-2023.pdf', 'page': 3}, page_content='iv\\nNational Ethics and Corruption Survey (NECS) 2023\\nEACC Research Report No. 15 of December 2023EACC ORGANIZATIONAL STATEMENTS \\nMission\\nVision\\nCore Values\\nIntegrity\\nInnovationTeam Work Fidelity to the\\nLaw\\nProfessionalismAn Integrity and \\nValues-Driven Kenyan SocietyTo promote integrity and \\ncombat corruption through \\nlaw enforcement, prevention \\nand educationOur Mandate\\nTo combat and prevent \\ncorruption, economic crime and \\nunethical conduct in Kenya \\nthrough law enforcement,')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = \"deepset/roberta-base-squad2\"\n",
    "# Default sentence transfromer is \"sentence-transformers/all-mpnet-base-v2\"\n",
    "import sentence_transformers\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the vector store (save to disk)\n",
    "db = Chroma.from_documents(chunks, embeddings_model, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is the most corrupt ministry?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transport, Infrastructure, Housing, Urban Development and Public Works (5.8%), Ministry of Education \n",
      "(5.5%) and Ministry of Defense (5.4%). This is as presented in Figure 3.35.\n",
      "Figure 3.35: Ministries perceived to be most prone to Corruption and Unethical Conduct\n",
      "3.6.8.2 Government Departments and Agencies Perceived to be most prone to Corruption and \n",
      "Unethical Practices\n",
      "Government Departments and Agencies perceived to be most prone to corruption are the Police\n"
     ]
    }
   ],
   "source": [
    "# retrieve from vector db (load from disk) with query\n",
    "db2 = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings_model)\n",
    "retrieved_docs = db2.similarity_search(query)\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the retriever\n",
    "retriever = db2.as_retriever(\n",
    "    search_type=\"mmr\", #similarity\n",
    "    search_kwargs={'k': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer object by loading the pretrained \"Intel/dynamic_tinybert\" tokenizer.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Intel/dynamic_tinybert\")\n",
    "\n",
    "# Create a question-answering model object by loading the pretrained \"Intel/dynamic_tinybert\" model.\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"Intel/dynamic_tinybert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model name you want to use\n",
    "model_name = \"Intel/dynamic_tinybert\"\n",
    "\n",
    "# Load the tokenizer associated with the specified model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Define a question-answering pipeline using the model and tokenizer\n",
    "question_answer = pipeline(\n",
    "    \"question-answering\", \n",
    "    model=model_name, \n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Create an instance of the HuggingFacePipeline, which wraps the question-answering pipeline\n",
    "# with additional model-specific arguments (temperature and max_length)\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=question_answer,\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 5.8%\n"
     ]
    }
   ],
   "source": [
    "question = \"Percentages of corruption in various ministries?\"\n",
    "\n",
    "def err_remove(er):\n",
    "    lin = \"------------\"\n",
    "    er = str(er)\n",
    "    start_index = er.find(lin) + len(lin)\n",
    "    end_index = er.rfind(lin)\n",
    "    answer = er[start_index:end_index].strip()\n",
    "    return answer\n",
    "\n",
    "try:\n",
    "    # Use the pipeline directly for question answering\n",
    "    context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "    result = question_answer(question=question, context=context)\n",
    "    answer = result['answer']\n",
    "    print(\"Answer:\", answer)  # Print the answer if successful\n",
    "except Exception as error:\n",
    "    answer = err_remove(error)\n",
    "    print(\"Error Answer:\", answer)  # Print the error answer if an exception occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
